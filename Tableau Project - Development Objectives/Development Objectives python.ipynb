{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99105ea9",
   "metadata": {},
   "source": [
    "Below is the original Python code. Includes data cleaning, pre-processing and categorizing.\n",
    "\n",
    "* AI assisted to format the code with comments and better readability for portfolio purposes.\n",
    "* Note that the code does not run as the input file is not present in this repository. It is only for reference purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d04ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Configuration flag - controls whether we remove exact duplicate rows\n",
    "# (same ID + Activity + Development Objective combination)\n",
    "DEDUPLICATE_INPUT = True\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Load the source Excel file\n",
    "input_file = \"input_file_example.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Read Excel, forcing certain columns to be read as strings (preserves leading zeros, etc.)\n",
    "    df = pd.read_excel(\n",
    "        input_file,\n",
    "        sheet_name=\"Sheet1\",\n",
    "        converters={\n",
    "            \"ID\": str,\n",
    "            \"Activity\": str,\n",
    "            \"Development Objective\": str\n",
    "        }\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error reading Excel file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Define cleaning functions for each key column\n",
    "\n",
    "def clean_activity(value):\n",
    "    \"\"\"Clean Activity column: remove control characters, handle various forms of missing/empty values\"\"\"\n",
    "    value = str(value).strip()                         # Convert to string + remove leading/trailing whitespace\n",
    "    value = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', value) # Remove all control characters\n",
    "    # Treat various representations of \"missing\" as \"N/A\"\n",
    "    if pd.isna(value) or value.lower() in [\"\", \"nan\", \"none\", \"null\", \"\\xa0\"]:\n",
    "        return \"N/A\"\n",
    "    if value.lower() in [\"n/a\", \"na\"]:\n",
    "        return \"N/A\"\n",
    "    return value\n",
    "\n",
    "def clean_id(value):\n",
    "    \"\"\"Clean ID column: similar logic but different default for missing values\"\"\"\n",
    "    value = str(value).strip()\n",
    "    value = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', value)\n",
    "    if pd.isna(value) or value.lower() in [\"\", \"nan\", \"none\", \"null\", \"\\xa0\"]:\n",
    "        return \"Unknown_ID\"\n",
    "    return value\n",
    "\n",
    "def clean_dev_objective(value):\n",
    "    \"\"\"Clean Development Objective - almost same logic as Activity\"\"\"\n",
    "    value = str(value).strip()\n",
    "    value = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', value)\n",
    "    if pd.isna(value) or value.lower() in [\"\", \"nan\", \"none\", \"null\", \"\\xa0\"]:\n",
    "        return \"N/A\"\n",
    "    if value.lower() in [\"n/a\", \"na\"]:\n",
    "        return \"N/A\"\n",
    "    return value\n",
    "\n",
    "# Apply cleaning functions to the three main columns\n",
    "df[\"Activity\"] = df[\"Activity\"].apply(clean_activity)\n",
    "df[\"ID\"] = df[\"ID\"].apply(clean_id)\n",
    "df[\"Development Objective\"] = df[\"Development Objective\"].apply(clean_dev_objective)\n",
    "\n",
    "# Extra safety: fill any remaining NaN values after cleaning\n",
    "df[\"Activity\"] = df[\"Activity\"].fillna(\"N/A\")\n",
    "df[\"ID\"] = df[\"ID\"].fillna(\"Unknown_ID\")\n",
    "df[\"Development Objective\"] = df[\"Development Objective\"].fillna(\"N/A\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Show basic statistics before any deduplication\n",
    "print(f\"Initial input records: {len(df)}\")\n",
    "print(f\"Unique IDs: {df['ID'].nunique()}\")\n",
    "print(f\"Unique Activities: {df['Activity'].nunique()}\")\n",
    "print(f\"Unique Development Objectives: {df['Development Objective'].nunique()}\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Check for exact duplicates on the business key (ID + Activity + Dev Objective)\n",
    "id_activity_dev_counts = df.groupby(\n",
    "    [\"ID\", \"Activity\", \"Development Objective\"]\n",
    ").size().reset_index(name=\"count\")\n",
    "\n",
    "duplicates_id_activity_dev = id_activity_dev_counts[\n",
    "    id_activity_dev_counts[\"count\"] > 1\n",
    "][[\"ID\", \"Activity\", \"Development Objective\", \"count\"]]\n",
    "\n",
    "if not duplicates_id_activity_dev.empty:\n",
    "    print(f\"Found {len(duplicates_id_activity_dev)} duplicate ID-Activity-Development Objective pairs:\")\n",
    "    print(duplicates_id_activity_dev.head(10))\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Optional deduplication step (controlled by config flag)\n",
    "if DEDUPLICATE_INPUT:\n",
    "    initial_count = len(df)\n",
    "    # Keep first occurrence only when all three key columns match\n",
    "    df = df.drop_duplicates(subset=[\"ID\", \"Activity\", \"Development Objective\"])\n",
    "    print(f\"Deduplicated input: {initial_count} → {len(df)} records\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Create a surrogate key that should be unique per logical record\n",
    "# Format: ID_Activity_DevObjective_rowindex\n",
    "df[\"Unique_Record_ID\"] = df.apply(\n",
    "    lambda x: f\"{x['ID']}_{x['Activity']}_{x['Development Objective']}_{x.name}\"\n",
    "    if pd.notna(x['ID']) and pd.notna(x['Activity']) and pd.notna(x['Development Objective'])\n",
    "    else f\"Unknown_{x.name}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Unique Unique_Record_IDs after deduplication: {df['Unique_Record_ID'].nunique()}\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Save intermediate debug files\n",
    "df.to_csv(\"input_debug.csv\", index=False)\n",
    "unique_activities = pd.DataFrame(df[\"Activity\"].unique(), columns=[\"Activity\"])\n",
    "unique_activities.to_csv(\"unique_activities_debug.csv\", index=False)\n",
    "\n",
    "print(\"Raw input saved to 'input_debug.csv'\")\n",
    "print(\"Unique activities saved to 'unique_activities_debug.csv'\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Report how many records ended up with placeholder values\n",
    "blank_activities = df[df[\"Activity\"] == \"N/A\"][[\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]]\n",
    "if not blank_activities.empty:\n",
    "    print(f\"Found {len(blank_activities)} N/A or blank activities:\")\n",
    "    print(blank_activities.head(10))\n",
    "\n",
    "blank_ids = df[df[\"ID\"] == \"Unknown_ID\"][[\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]]\n",
    "if not blank_ids.empty:\n",
    "    print(f\"Found {len(blank_ids)} Unknown_ID assignments:\")\n",
    "    print(blank_ids.head(10))\n",
    "\n",
    "blank_dev_objectives = df[df[\"Development Objective\"] == \"N/A\"][[\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]]\n",
    "if not blank_dev_objectives.empty:\n",
    "    print(f\"Found {len(blank_dev_objectives)} N/A Development Objectives:\")\n",
    "    print(blank_dev_objectives.head(10))\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Keyword-based classification rules (multi-label possible)\n",
    "activity_categories = {\n",
    "    \"Training / Workshop\": [\"training\", \"workshop\", \"course\", \"enroll\", \"structured\", \"class\", \"program\", \"internal courses\", \"external training\", \"leadership training\", \"management training\", \"ai course\", \"bim training\", \"business writing course\", \"project management training\", \"safety training\", \"communication training\", \"technical training\", \"refresher training\", \"in-house training\", \"classroom training\", \"job rotation\", \"couse\", \"technovation talk\", \"business talk series\"],\n",
    "    \"Seminar\": [\"seminar\", \"session\", \"sharing session\", \"conference\", \"webinar\", \"forum\", \"exhibition\", \"cpd seminar\", \"vendor demonstration\", \"case study sharing\", \"e-talks\", \"symposium\", \"town hall\", \"internal talks\", \"technology briefings\", \"briefing sessions\", \"panel discussions\", \"6g summit\", \"expo critical communication\", \"summit\", \"expo\"],\n",
    "    \"Self-Study\": [\"self-study\", \"self-learning\", \"youtube\", \"books\", \"mobile app\", \"reading\", \"online learning\", \"e-learning\", \"self-paced\", \"web-based\", \"mylearning\", \"self-development\", \"audio books\", \"self reading\", \"update oneself\", \"chat gpt\", \"chatgpt\", \"deepseek\", \"comfyui\", \"navisworks\", \"rhino\", \"intranet\", \"icao\", \"redhat\", \"primavera\"],\n",
    "    \"Language Exchange\": [\"language exchange\", \"conversational\", \"practice conversational\", \"language practice\", \"language partner\", \"toastmasters\", \"impromptu speaking\", \"public speaking\", \"cantonese lessons\", \"writing practice\"],\n",
    "    \"Professional Development\": [\"professional development\", \"enhance skills\", \"technical knowledge\", \"problem solving\", \"leadership\", \"management skills\", \"people management\", \"people mindset\", \"culture change\", \"emotional intelligence\", \"change management\", \"time management\", \"communication skill\", \"technical report writing\", \"minto pyramid principle\", \"intercultural communication\", \"business acumen\", \"strategic thinking\", \"commercial awareness\", \"creative problem-solving\", \"corporate perspective\", \"growth mindset\", \"confidence\", \"persuasiveness\", \"delegation\", \"negotiation\", \"trust\", \"rapport\", \"high-quality work\", \"presentation skills\", \"business analytics\", \"industry acumen\", \"decision-making\"],\n",
    "    \"Involvement in Projects\": [\"project\", \"implement\", \"project work\", \"hands-on\", \"practical application\", \"involve\", \"administrative work\", \"project assignments\", \"nec\", \"special project\", \"operation model review\", \"handover process\", \"attachment specialist\", \"design development\", \"construction management\", \"system development\", \"lidar drone\", \"bim clash\"],\n",
    "    \"Mentoring / Coaching\": [\"mentoring\", \"coaching\", \"guidance\", \"mentor\", \"tutoring\", \"one-on-one\", \"feedback\", \"supervisor\", \"learn from\", \"knowledge sharing\", \"facilitator\", \"support assistance\", \"transfer know-how\", \"develop subordinates\", \"guide team\"],\n",
    "    \"Certification\": [\"certification\", \"certificate\", \"accreditation\", \"credential\", \"exam preparation\", \"register electrical worker\", \"intercultural communication certification\", \"chartered engineer\", \"nace coating\", \"cissp\", \"rew grade\", \"cic ccbm\"],\n",
    "    \"Networking\": [\"networking\", \"meetup\", \"industry event\", \"professional network\", \"collaboration\", \"professional events\", \"expand connections\", \"knowledge and experience exchange\", \"build relationships\", \"stakeholder\", \"public consultation\", \"business meetings\", \"cross-department\", \"event\", \"supplier meetings\", \"cross-industry exchange\", \"professional organizations\", \"senior management discussions\"],\n",
    "    \"Research\": [\"research\", \"study\", \"analysis\", \"investigation\", \"data analysis\", \"mini research project\", \"product features\", \"business model\", \"new technologies\", \"market research\", \"system assessment\", \"code requirements\", \"literature review\"],\n",
    "    \"Safety / Compliance\": [\"safety\", \"emergency response\", \"business continuity\", \"statutory requirement\", \"safety forums\", \"safety workshops\", \"risk management\", \"regulatory compliance\"],\n",
    "    \"Site Visit\": [\"visit\", \"data center\", \"site visit\", \"facility tour\", \"travel technology\", \"site inspection\"],\n",
    "    \"Team Building\": [\"team building\", \"teamwork\", \"collaboration\", \"interpersonal relationship\", \"people meetings\", \"cross-department\", \"collaborative decision-making\", \"team efficiency\", \"team discussions\"],\n",
    "    \"General Development\": [\"to be update\", \"general development\", \"showcase\", \"general practices\", \"continuous engagement\", \"any suitable involvement\", \"explore industrial options\"],\n",
    "    \"On-the-Job Learning\": [\"on-the-job\", \"on job\", \"practical experience\", \"learn from bosses\", \"practical learning\", \"duty attachment\", \"role rotation\"],\n",
    "    \"Operational Duties\": [\"routine duty\", \"daily operations\", \"monitor progress\", \"site supervision\", \"operational requirements\", \"handover process\", \"contractor coordination\", \"works monitoring\", \"document preparation\"],\n",
    "    \"Leadership / Management\": [\"lead\", \"manage\", \"supervise\", \"team leadership\", \"strategic initiatives\", \"business decision\", \"set goals\", \"manage capex\", \"team coordination\"],\n",
    "    \"Event Planning\": [\"arrange events\", \"organise activities\", \"event planning\", \"promotion activities\", \"launch event\", \"marketing activities\"]\n",
    "}\n",
    "\n",
    "def classify_activity(activity):\n",
    "    \"\"\"Rule-based classifier: returns list of matching categories (can be multiple)\"\"\"\n",
    "    activity_clean = str(activity).lower().strip(\"- \")\n",
    "    activity_clean = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', activity_clean)\n",
    "    \n",
    "    if activity_clean.lower() == \"n/a\":\n",
    "        return [\"Other\"]\n",
    "    \n",
    "    matching_categories = set()\n",
    "    for category, keywords in activity_categories.items():\n",
    "        if any(keyword in activity_clean for keyword in keywords):\n",
    "            matching_categories.add(category)\n",
    "    \n",
    "    return list(matching_categories) if matching_categories else [\"Other\"]\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Create one row per category (exploding multi-category records)\n",
    "new_rows = []\n",
    "unique_inputs = set()\n",
    "\n",
    "# Group by the business key + surrogate key\n",
    "for (id_val, activity, dev_objective, unique_record_id), group in df.groupby(\n",
    "    [\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]\n",
    "):\n",
    "    unique_inputs.add((id_val, activity, dev_objective, unique_record_id))\n",
    "    \n",
    "    # Get list of categories for this activity\n",
    "    categories = classify_activity(activity)\n",
    "    if not categories:\n",
    "        categories = [\"Other\"]\n",
    "    \n",
    "    # Take the first row of the group as base\n",
    "    base_row = group.iloc[0].copy()\n",
    "    \n",
    "    # Create one new row per category\n",
    "    for category in categories:\n",
    "        new_row = base_row.copy()\n",
    "        new_row[\"Activity Category\"] = category\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Convert list of dicts/series → final DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Final statistics\n",
    "print(f\"Unique ID-Activity-Development Objective-Unique_Record_ID pairs in input: {len(unique_inputs)}\")\n",
    "print(f\"Total output records (with multi-category duplicates): {len(new_df)}\")\n",
    "print(f\"Unique Unique_Record_IDs in output: {new_df['Unique_Record_ID'].nunique()}\")\n",
    "\n",
    "other_activities = new_df[new_df[\"Activity Category\"] == \"Other\"][\n",
    "    [\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]\n",
    "]\n",
    "print(f\"Total activities classified as Other: {len(other_activities)}\")\n",
    "if not other_activities.empty:\n",
    "    print(\"Sample of activities classified as Other:\")\n",
    "    print(other_activities.head(10))\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Save results and debug files\n",
    "new_df.to_excel(\"output_file_example.xlsx\", index=False)\n",
    "unique_pairs = pd.DataFrame(list(unique_inputs), columns=[\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"])\n",
    "unique_pairs.to_csv(\"unique_pairs_debug.csv\", index=False)\n",
    "\n",
    "category_counts = new_df.groupby(\"Activity Category\")[\"Unique_Record_ID\"].nunique().reset_index(name=\"Unique_Record_Count\")\n",
    "category_counts.to_csv(\"category_counts_debug.csv\", index=False)\n",
    "\n",
    "print(\"Output saved to 'output_file_example.xlsx'\")\n",
    "print(\"Unique pairs saved to 'unique_pairs_debug.csv'\")\n",
    "print(\"Category counts saved to 'category_counts_debug.csv'\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Show preview of final result\n",
    "print(\"\\nSample of categorized DataFrame:\")\n",
    "print(new_df[[\"ID\", \"Activity\", \"Development Objective\", \"Activity Category\", \"Unique_Record_ID\"]].head(20))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
