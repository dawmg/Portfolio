{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99105ea9",
   "metadata": {},
   "source": [
    "Below is the original Python code. Includes data cleaning, pre-processing and categorizing.\n",
    "\n",
    "* AI assisted code writing. AI was also used to format the code with comments and better readability for portfolio purposes.\n",
    "* Note that the code does not run 1:1 compared to what is seen in the Tableau dashboard. It is only for reference purposes. But, the logic is the same throughout the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d04ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Configuration flag - controls whether we remove exact duplicate rows\n",
    "# (same ID + Activity + Development Objective combination)\n",
    "DEDUPLICATE_INPUT = True\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Load the source Excel file\n",
    "input_file = \"input_file_example.xlsx\" # In this case, the data source\n",
    "\n",
    "try:\n",
    "    # Read Excel, forcing certain columns to be read as strings (preserves leading zeros, etc.)\n",
    "    df = pd.read_excel(\n",
    "        input_file,\n",
    "        sheet_name=\"Sheet1\",\n",
    "        converters={\n",
    "            \"ID\": str,\n",
    "            \"Activity\": str,\n",
    "            \"Development Objective\": str\n",
    "        }\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error reading Excel file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Define cleaning functions for each key column\n",
    "\n",
    "def clean_activity(value):\n",
    "    \"\"\"Clean Activity column: remove control characters, handle various forms of missing/empty values\"\"\"\n",
    "    value = str(value).strip()                         # Convert to string + remove leading/trailing whitespace\n",
    "    value = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', value) # Remove all control characters\n",
    "    # Treat various representations of \"missing\" as \"N/A\"\n",
    "    if pd.isna(value) or value.lower() in [\"\", \"nan\", \"none\", \"null\", \"\\xa0\"]:\n",
    "        return \"N/A\"\n",
    "    if value.lower() in [\"n/a\", \"na\"]:\n",
    "        return \"N/A\"\n",
    "    return value\n",
    "\n",
    "def clean_id(value):\n",
    "    \"\"\"Clean ID column: similar logic but different default for missing values\"\"\"\n",
    "    value = str(value).strip()\n",
    "    value = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', value)\n",
    "    if pd.isna(value) or value.lower() in [\"\", \"nan\", \"none\", \"null\", \"\\xa0\"]:\n",
    "        return \"Unknown_ID\"\n",
    "    return value\n",
    "\n",
    "def clean_dev_objective(value):\n",
    "    \"\"\"Clean Development Objective - almost same logic as Activity\"\"\"\n",
    "    value = str(value).strip()\n",
    "    value = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', value)\n",
    "    if pd.isna(value) or value.lower() in [\"\", \"nan\", \"none\", \"null\", \"\\xa0\"]:\n",
    "        return \"N/A\"\n",
    "    if value.lower() in [\"n/a\", \"na\"]:\n",
    "        return \"N/A\"\n",
    "    return value\n",
    "\n",
    "# Apply cleaning functions to the three main columns\n",
    "df[\"Activity\"] = df[\"Activity\"].apply(clean_activity)\n",
    "df[\"ID\"] = df[\"ID\"].apply(clean_id)\n",
    "df[\"Development Objective\"] = df[\"Development Objective\"].apply(clean_dev_objective)\n",
    "\n",
    "# Extra safety: fill any remaining NaN values after cleaning\n",
    "df[\"Activity\"] = df[\"Activity\"].fillna(\"N/A\")\n",
    "df[\"ID\"] = df[\"ID\"].fillna(\"Unknown_ID\")\n",
    "df[\"Development Objective\"] = df[\"Development Objective\"].fillna(\"N/A\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Show basic statistics before any deduplication\n",
    "print(f\"Initial input records: {len(df)}\")\n",
    "print(f\"Unique IDs: {df['ID'].nunique()}\")\n",
    "print(f\"Unique Activities: {df['Activity'].nunique()}\")\n",
    "print(f\"Unique Development Objectives: {df['Development Objective'].nunique()}\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Check for exact duplicates on the business key (ID + Activity + Dev Objective)\n",
    "id_activity_dev_counts = df.groupby(\n",
    "    [\"ID\", \"Activity\", \"Development Objective\"]\n",
    ").size().reset_index(name=\"count\")\n",
    "\n",
    "duplicates_id_activity_dev = id_activity_dev_counts[\n",
    "    id_activity_dev_counts[\"count\"] > 1\n",
    "][[\"ID\", \"Activity\", \"Development Objective\", \"count\"]]\n",
    "\n",
    "if not duplicates_id_activity_dev.empty:\n",
    "    print(f\"Found {len(duplicates_id_activity_dev)} duplicate ID-Activity-Development Objective pairs:\")\n",
    "    print(duplicates_id_activity_dev.head(10))\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Optional deduplication step (controlled by config flag)\n",
    "if DEDUPLICATE_INPUT:\n",
    "    initial_count = len(df)\n",
    "    # Keep first occurrence only when all three key columns match\n",
    "    df = df.drop_duplicates(subset=[\"ID\", \"Activity\", \"Development Objective\"])\n",
    "    print(f\"Deduplicated input: {initial_count} → {len(df)} records\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Create a surrogate key that should be unique per logical record\n",
    "# Format: ID_Activity_DevObjective_rowindex\n",
    "df[\"Unique_Record_ID\"] = df.apply(\n",
    "    lambda x: f\"{x['ID']}_{x['Activity']}_{x['Development Objective']}_{x.name}\"\n",
    "    if pd.notna(x['ID']) and pd.notna(x['Activity']) and pd.notna(x['Development Objective'])\n",
    "    else f\"Unknown_{x.name}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Unique Unique_Record_IDs after deduplication: {df['Unique_Record_ID'].nunique()}\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Save intermediate debug files\n",
    "df.to_csv(\"input_debug.csv\", index=False)\n",
    "unique_activities = pd.DataFrame(df[\"Activity\"].unique(), columns=[\"Activity\"])\n",
    "unique_activities.to_csv(\"unique_activities_debug.csv\", index=False)\n",
    "\n",
    "print(\"Raw input saved to 'input_debug.csv'\")\n",
    "print(\"Unique activities saved to 'unique_activities_debug.csv'\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Report how many records ended up with placeholder values\n",
    "blank_activities = df[df[\"Activity\"] == \"N/A\"][[\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]]\n",
    "if not blank_activities.empty:\n",
    "    print(f\"Found {len(blank_activities)} N/A or blank activities:\")\n",
    "    print(blank_activities.head(10))\n",
    "\n",
    "blank_ids = df[df[\"ID\"] == \"Unknown_ID\"][[\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]]\n",
    "if not blank_ids.empty:\n",
    "    print(f\"Found {len(blank_ids)} Unknown_ID assignments:\")\n",
    "    print(blank_ids.head(10))\n",
    "\n",
    "blank_dev_objectives = df[df[\"Development Objective\"] == \"N/A\"][[\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]]\n",
    "if not blank_dev_objectives.empty:\n",
    "    print(f\"Found {len(blank_dev_objectives)} N/A Development Objectives:\")\n",
    "    print(blank_dev_objectives.head(10))\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Keyword-based classification rules (multi-label possible)\n",
    "activity_categories = {\n",
    "    \"Training / Workshop\": [\"REDACTED\"],\n",
    "    \"Seminar\": [\"REDACTED\"],\n",
    "    \"Self-Study\": [\"REDACTED\"],\n",
    "    \"Language Exchange\": [\"REDACTED\"],\n",
    "    \"Professional Development\": [\"REDACTED\"],\n",
    "    \"Involvement in Projects\": [\"REDACTED\"],\n",
    "    \"Mentoring / Coaching\": [\"REDACTED\"],\n",
    "    \"Certification\": [\"REDACTED\"],\n",
    "    \"Networking\": [\"REDACTED\"],\n",
    "    \"Research\": [\"REDACTED\"],\n",
    "    \"Safety / Compliance\": [\"REDACTED\"],\n",
    "    \"Site Visit\": [\"REDACTED\"],\n",
    "    \"Team Building\": [\"REDACTED\"],\n",
    "    \"General Development\": [\"REDACTED\"],\n",
    "    \"On-the-Job Learning\": [\"REDACTED\"],\n",
    "    \"Operational Duties\": [\"REDACTED\"],\n",
    "    \"Leadership / Management\": [\"REDACTED\"],\n",
    "    \"Event Planning\": [\"REDACTED\"]\n",
    "}\n",
    "\n",
    "def classify_activity(activity):\n",
    "    \"\"\"Rule-based classifier: returns list of matching categories (can be multiple)\"\"\"\n",
    "    activity_clean = str(activity).lower().strip(\"- \")\n",
    "    activity_clean = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', activity_clean)\n",
    "    \n",
    "    if activity_clean.lower() == \"n/a\":\n",
    "        return [\"Other\"]\n",
    "    \n",
    "    matching_categories = set()\n",
    "    for category, keywords in activity_categories.items():\n",
    "        if any(keyword in activity_clean for keyword in keywords):\n",
    "            matching_categories.add(category)\n",
    "    \n",
    "    return list(matching_categories) if matching_categories else [\"Other\"]\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Create one row per category (exploding multi-category records)\n",
    "new_rows = []\n",
    "unique_inputs = set()\n",
    "\n",
    "# Group by the business key + surrogate key\n",
    "for (id_val, activity, dev_objective, unique_record_id), group in df.groupby(\n",
    "    [\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]\n",
    "):\n",
    "    unique_inputs.add((id_val, activity, dev_objective, unique_record_id))\n",
    "    \n",
    "    # Get list of categories for this activity\n",
    "    categories = classify_activity(activity)\n",
    "    if not categories:\n",
    "        categories = [\"Other\"]\n",
    "    \n",
    "    # Take the first row of the group as base\n",
    "    base_row = group.iloc[0].copy()\n",
    "    \n",
    "    # Create one new row per category\n",
    "    for category in categories:\n",
    "        new_row = base_row.copy()\n",
    "        new_row[\"Activity Category\"] = category\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Convert list of dicts/series → final DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Final statistics\n",
    "print(f\"Unique ID-Activity-Development Objective-Unique_Record_ID pairs in input: {len(unique_inputs)}\")\n",
    "print(f\"Total output records (with multi-category duplicates): {len(new_df)}\")\n",
    "print(f\"Unique Unique_Record_IDs in output: {new_df['Unique_Record_ID'].nunique()}\")\n",
    "\n",
    "other_activities = new_df[new_df[\"Activity Category\"] == \"Other\"][\n",
    "    [\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"]\n",
    "]\n",
    "print(f\"Total activities classified as Other: {len(other_activities)}\")\n",
    "if not other_activities.empty:\n",
    "    print(\"Sample of activities classified as Other:\")\n",
    "    print(other_activities.head(10))\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Save results and debug files\n",
    "new_df.to_excel(\"output_file_example.xlsx\", index=False)\n",
    "unique_pairs = pd.DataFrame(list(unique_inputs), columns=[\"ID\", \"Activity\", \"Development Objective\", \"Unique_Record_ID\"])\n",
    "unique_pairs.to_csv(\"unique_pairs_debug.csv\", index=False)\n",
    "\n",
    "category_counts = new_df.groupby(\"Activity Category\")[\"Unique_Record_ID\"].nunique().reset_index(name=\"Unique_Record_Count\")\n",
    "category_counts.to_csv(\"category_counts_debug.csv\", index=False)\n",
    "\n",
    "print(\"Output saved to 'output_file_example.xlsx'\")\n",
    "print(\"Unique pairs saved to 'unique_pairs_debug.csv'\")\n",
    "print(\"Category counts saved to 'category_counts_debug.csv'\")\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# Show preview of final result\n",
    "print(\"\\nSample of categorized DataFrame:\")\n",
    "print(new_df[[\"ID\", \"Activity\", \"Development Objective\", \"Activity Category\", \"Unique_Record_ID\"]].head(20))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
